- **ex5.m** - Matlab script for the exercise
- **ex5data1.mat** - Dataset containing historical records on the change in the water level, x, and the amount of water flowing out of the dam, y
- **featureNormalize.m** - Feature normalization function
- **fmincg.m** - Function minimization routine (similar to fminunc)
- **plotFit.m** - Plot a polynomial fit
- **trainLinearReg.m** - Trains linear regression using your cost function
- **linearRegCostFunction.m** - Regularized linear regression cost function, expected cost function output of 303.993 and gradient of [-15.30; 598.250] at theta [1; -1]
- **learningCurve.m** - Generates a learning curve
- **polyFeatures.m** - Maps data into polynomial feature space
- **validationCurve.m** - Generates a cross validation curve

**Output**:
- Plot of the training data 
![training data plot.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/training%20data%20plot.jpg)

- Linear fit of training data 
![training data linear fit.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/training%20data%20linear%20fit.jpg)

- Plot of the linear regression learning curve 
![linear regression learning curve.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/linear%20regression%20learning%20curve.jpg)

- Plot of polynomial regression fit 
![polynomial regression fit.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/polynomial%20regression%20fit.jpg)

- Plot of the polynomial learning curve 
![polynomial learning curve.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/polynomial%20learning%20curve.jpg)

- Plot of selecting lambda using a cross validation set 
![selecting lambda.jpg](https://github.com/shngli/Machine-learning/blob/master/Linear%20Regression%20Bias%20vs%20Variance/selecting%20lambda.jpg)
